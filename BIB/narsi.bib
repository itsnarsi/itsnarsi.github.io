@article{reddy2020generalizable,
  title={Generalizable deep features for ocular biometrics},
  author={Reddy, Narsi and Rattani, Ajita and Derakhshani, Reza},
  journal={Image and Vision Computing},
  volume={103},
  pages={103996},
  year={2020},
  publisher={Elsevier},
  url={https://www.researchgate.net/publication/343521546_Generalizable_deep_features_for_ocular_biometrics}
}

@INPROCEEDINGS{Narsi2020Emotion,
  author={N. {Reddy} and R. {Derakhshani}},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Emotion Detection using Periocular Region: A Cross-Dataset Study}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/IJCNN48605.2020.9207542},
  url={https://www.researchgate.net/publication/344877782_Emotion_Detection_using_Periocular_Region_A_Cross-Dataset_Study}}

@inproceedings{Narsi2019Unsupervised,
  title={Robust Subject-invariant Feature Learning for Ocular Biometrics in Visible
Spectrum},
  author={Reddy, Narsi and Rattani, Ajita and Derakhshani, Reza},
  booktitle={2019 IEEE 10th International Conference on Biometrics Theory, Applications and Systems (BTAS)},
  pages={1--6},
  year={2019},
  organization={IEEE}
}

@inproceedings{reddy2018ocularnet,
  title={OcularNet: Deep Patch-based Ocular Biometric Recognition},
  author={Reddy, Narsi and Rattani, Ajita and Derakhshani, Reza},
  booktitle={2018 IEEE International Symposium on Technologies for Homeland Security (HST)},
  pages={1--6},
  year={2018},
  organization={IEEE}
}

@inproceedings{reddycomparison,
  title={Comparison of Deep Learning Models for Biometric-based Mobile User Authentication},
  author={Reddy, Narsi and Rattani, Ajita and Derakhshani, Reza},
  booktitle={2018 IEEE 9th International Conference on Biometrics Theory, Applications and Systems (BTAS)},
  year={2018},
  organization={IEEE}
}

@inproceedings{rattani2018multi,
  title={Multi-biometric convolutional neural networks for mobile user authentication},
  author={Rattani, Ajita and Reddy, Narsi and Derakhshani, Reza},
  booktitle={2018 IEEE International Symposium on Technologies for Homeland Security (HST)},
  pages={1--6},
  year={2018},
  organization={IEEE}
}

@InProceedings{Reddy_2018_CVPR_Workshops,
author = {Reddy, Narsi and Fahim Noor, Dewan and Li, Zhu and Derakhshani, Reza},
title = {Multi-Frame Super Resolution for Ocular Biometrics},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month = {June},
year = {2018}
}

@ARTICLE{Rattani2018genderprediction,
   author = {Ajita Rattani, Narsi Reddy, Reza Derakhshani},
   keywords = {pre-trained network architectures;gender information;mobile healthcare system;automated gender prediction;image retrieval system;human–computer interaction;smartphone-based ocular images;integrated biometric authentication;convolutional neural network architectures;anonymous customised advertisement system;smartphone devices;},
   ISSN = {2047-4938},
   language = {English},
   abstract = {Automated gender prediction has drawn significant interest in numerous applications such as surveillance, human–computer interaction, anonymous customised advertisement system, image retrieval system, and biometrics. In the context of smartphone devices, gender information has been used to enhance the accuracy of the integrated biometric authentication and mobile healthcare system. Here, the authors thoroughly investigate gender prediction from ocular images acquired using front-facing cameras of smartphones. This is a new problem as previous research in this area has not explored RGB ocular images captured by smartphones. The authors used deep learning for the task. Specifically, pre-trained and custom convolutional neural network architectures have been implemented for gender prediction. Multi-classifier fusion has been used to improve the prediction accuracy. Further, evaluation of off-the-self-texture descriptors and study of human ability in gender prediction has been conducted for comparative analysis.},
   title = {Convolutional neural networks for gender prediction from smartphone-based ocular images},
   journal = {IET Biometrics},
   year = {2018},
   month = {January},
   publisher ={Institution of Engineering and Technology},
   copyright = {© The Institution of Engineering and Technology},
   url = {http://digital-library.theiet.org/content/journals/10.1049/iet-bmt.2017.0171}
}

@CONFERENCE {rattani2017ageclass,
    author    = "Ajita Rattani, Narsi Reddy, Reza Derakhshani",
    title     = "Convolutional Neural Network for Age Classification from Smart-phone based Ocular Images",
    booktitle = "Intl Joint Conference on Biometrics, Special session on Ocular Biometrics in Visible spectrum, Denver, Colorado",
    year      = "2017"
}

@INPROCEEDINGS{7568948,
author={N. Reddy and A. Rattani and R. Derakhshani},
booktitle={2016 IEEE Symposium on Technologies for Homeland Security (HST)},
title={A robust scheme for iris segmentation in mobile environment},
year={2016},
pages={1-6},
abstract={With the advent of mobile ocular biometrics and ocular human-computer interactions (HCI), recent research has been focused on iris localization in the visible spectrum. Existing studies suggest that performance of the ocular HCI and biometric systems significantly degrades due to inaccurate iris segmentation, especially when operating in uncontrolled mobile environment which causes variations such as motion blur, specular reflection and illumination variation. This paper proposes a iris segmentation algorithm for visible spectrum which is based on the combination of K-means clustering and Daugman's integro-differential algorithm. Experimental investigation on the publicly available VISOB dataset prove the efficacy of the proposed approach. Experimental results show that iris segmentation increases 4 folds compared to Daugman's and 3.5 folds compared to Masek's methods. The proposed method also executes 5 times faster than Daugman's and 8 times faster than Masek's methods.},
keywords={human computer interaction;image motion analysis;iris recognition;mobile computing;pattern clustering;Daugman integro-differential algorithm;VISOB dataset;biometric systems;illumination variation;iris localization;iris segmentation algorithm;k-means clustering;mobile ocular biometrics;motion blur;ocular HCI;ocular human-computer interactions;robust scheme;specular reflection;uncontrolled mobile environment;visible spectrum;Clustering algorithms;Image segmentation;Iris;Iris recognition;Mobile communication;Iris segmentation;Mobile biometrics;Visible Spectrum},
doi={10.1109/THS.2016.7568948},
month={May},}